{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/dijk/ahf38/conda_envs/cst/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "cuda\n",
      "1.7.7\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device='cpu'\n",
    "print(device)\n",
    "import pytorch_lightning as pl\n",
    "print(pl.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jgG-sIIhFdDn",
    "outputId": "d23d495d-9cef-468f-f1a4-7898784c961a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 18 15:21:16 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-PCIE-40GB           On | 00000000:5E:00.0 Off |                    0 |\n",
      "| N/A   24C    P0               30W / 250W|      3MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, argparse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "import torch #Installed with conda install pytorch torchvision torchaudio cudatoolkit=11.6 -c pytorch -c conda-forge\n",
    "import glob\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import continuous_transformer.ContSpaceTime as ContSpaceTime\n",
    "from continuous_transformer.models_lightning import BERT_Model, BERT_LinearEncoder\n",
    "from continuous_transformer.continuous_utils import print_nvidia_smi, create_dataloaders_toydata\n",
    "from continuous_transformer.utils import set_seeds\n",
    "\n",
    "import pytorch_lightning as pl #Installed with pip install pytorch-lightning\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from continuous_transformer.sobolev_loss import sobolev_loss\n",
    "\n",
    "print_nvidia_smi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='CST')\n",
    "parser.add_argument('-root_path', metavar='DIR', default='/home/ahf38/palmer_scratch/cst_release', #'/home/ahf38/outputs/cst',\n",
    "                    help='path to dataset')\n",
    "\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model='cst'\n",
    "args.mode='train'\n",
    "args.seed = 1\n",
    "set_seeds(args.seed)\n",
    "args.batch_size = 10\n",
    "args.log_per_minibatch=True\n",
    "args.num_minibatches=2\n",
    "args.gpu_id = 0\n",
    "device = torch.device('cuda:'+str(args.gpu_id) if torch.cuda.is_available() else 'cpu')\n",
    "args.device = device\n",
    "\n",
    "args.num_dim_plot = 20\n",
    "args.lr_scheduler = None\n",
    "args.experiment_name = '50_IE_Spirals' #'Data_RandProj_20pcs_150frames', Data_20pcs_150frames\n",
    "args.data_dim = 'orig' #'Data_2D', 'Data_10D', 'Data_50D', 'Data_orig'\n",
    "args.randomly_drop_n_last_frames=None\n",
    "args.drop_n_last_frames = None\n",
    "args.num_points_for_c=10\n",
    "args.resume_from_checkpoint = False\n",
    "args.downsample_points=10\n",
    "args.num_seen_points = 0\n",
    "args.regularly_sampled=True\n",
    "args.validation_split=0.3\n",
    "args.use_first_n_frames=500\n",
    "args.derivtive_order_k = 1\n",
    "args.norm_power_p = 2\n",
    "\n",
    "args.compute_loss_whole_curve = False\n",
    "args.compute_loss_on_dummy_points = True\n",
    "\n",
    "args.one_curve_per_frame=True\n",
    "\n",
    "args.add_noise_to_input_data=.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HZYCb6WpFdDu",
    "outputId": "5ea73bfd-9331-4e32-8af9-bf33315be7f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  ./datasets/50_IE_Spirals.p\n",
      "dict_keys(['Data_orig'])\n",
      "dataset: train \tframes: 10 \tbatch_size: 10\n",
      "dataset: val \tframes: 10 \tbatch_size: 10\n"
     ]
    }
   ],
   "source": [
    "# -- load dataset\n",
    "dataloaders = create_dataloaders_toydata(path_file=r\"./datasets\", \n",
    "                                         experiment_name = args.experiment_name, #ToyData_100curves_160points_2D, ToyData_1curve_1kpoints_2D\n",
    "                                         use_first_n_frames=args.use_first_n_frames,\n",
    "                                         batch_size_segments=args.batch_size,\n",
    "                                         validation_split=args.validation_split,\n",
    "                                         regularly_sampled= args.regularly_sampled,\n",
    "                                         downsample_points=args.downsample_points,\n",
    "                                         args=args\n",
    "                                        )\n",
    "\n",
    "for dataloader in dataloaders:\n",
    "    print(f\"dataset: {dataloader} \\tframes: {len(dataloaders[dataloader].dataset)} \\tbatch_size: {dataloaders[dataloader].batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "INBVPQFmFdDv",
    "outputId": "5b12e527-5188-44d2-e473-25ebba2715e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs_.shape:  torch.Size([10, 10, 2, 1])\n",
      "ts_.shape:  torch.Size([10, 10])\n",
      "ids_.shape:  torch.Size([10])\n",
      "frames_to_drop_.shape:  torch.Size([10])\n",
      "tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n",
      "        1.0000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs_, ts_, ids_, frames_to_drop_ = next(iter(dataloaders['train']))\n",
    "print('obs_.shape: ',obs_.shape)\n",
    "print('ts_.shape: ',ts_.shape)\n",
    "print('ids_.shape: ',ids_.shape)\n",
    "print('frames_to_drop_.shape: ',frames_to_drop_.shape)\n",
    "\n",
    "idx_batch = 0\n",
    "# plt.plot(labels_tmp[idx_batch,:].flatten())\n",
    "%matplotlib inline\n",
    "fig,ax = plt.subplots(2,1,figsize=(20,10))\n",
    "ax = ax.ravel()\n",
    "for idx in range(2):\n",
    "    ax[idx].scatter(ts_[idx_batch], obs_[idx_batch,:,idx], vmin=-0.5, vmax=0.5)\n",
    "print(ts_[idx_batch])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qpeEyCJGFdDv",
    "outputId": "6c6bf246-ec82-4080-f6a5-3389d105cb00",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_to_experiment:  /home/ahf38/palmer_scratch/cst_release/BERT-50_IE_Spirals\n",
      "version:  6\n",
      "model_type:  50_IE_Spirals\n",
      "model type 'grid' not recognized, using 'linea_encoder' instead\n",
      "BERT_Model(\n",
      "  (model): BERT_LinearEncoder(\n",
      "    (transformer): Transformer(\n",
      "      (embed): Embeddings(\n",
      "        (pos_embed): Embedding(10, 32)\n",
      "        (pos_embed_3DLin): Linear(in_features=3, out_features=32, bias=True)\n",
      "        (norm): LayerNorm()\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (blocks): ModuleList(\n",
      "        (0): Block(\n",
      "          (attn): MultiHeadedSelfAttention(\n",
      "            (proj_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (proj_k): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (proj_v): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (drop): Dropout(p=0.8, inplace=False)\n",
      "          )\n",
      "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (norm1): LayerNorm()\n",
      "          (pwff): PositionWiseFeedForward(\n",
      "            (fc1): Linear(in_features=32, out_features=3072, bias=True)\n",
      "            (fc2): Linear(in_features=3072, out_features=32, bias=True)\n",
      "          )\n",
      "          (norm2): LayerNorm()\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): Block(\n",
      "          (attn): MultiHeadedSelfAttention(\n",
      "            (proj_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (proj_k): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (proj_v): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (drop): Dropout(p=0.8, inplace=False)\n",
      "          )\n",
      "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (norm1): LayerNorm()\n",
      "          (pwff): PositionWiseFeedForward(\n",
      "            (fc1): Linear(in_features=32, out_features=3072, bias=True)\n",
      "            (fc2): Linear(in_features=3072, out_features=32, bias=True)\n",
      "          )\n",
      "          (norm2): LayerNorm()\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): Block(\n",
      "          (attn): MultiHeadedSelfAttention(\n",
      "            (proj_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (proj_k): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (proj_v): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (drop): Dropout(p=0.8, inplace=False)\n",
      "          )\n",
      "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (norm1): LayerNorm()\n",
      "          (pwff): PositionWiseFeedForward(\n",
      "            (fc1): Linear(in_features=32, out_features=3072, bias=True)\n",
      "            (fc2): Linear(in_features=3072, out_features=32, bias=True)\n",
      "          )\n",
      "          (norm2): LayerNorm()\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (3): Block(\n",
      "          (attn): MultiHeadedSelfAttention(\n",
      "            (proj_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (proj_k): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (proj_v): Linear(in_features=32, out_features=32, bias=True)\n",
      "            (drop): Dropout(p=0.8, inplace=False)\n",
      "          )\n",
      "          (proj): Linear(in_features=32, out_features=32, bias=True)\n",
      "          (norm1): LayerNorm()\n",
      "          (pwff): PositionWiseFeedForward(\n",
      "            (fc1): Linear(in_features=32, out_features=3072, bias=True)\n",
      "            (fc2): Linear(in_features=3072, out_features=32, bias=True)\n",
      "          )\n",
      "          (norm2): LayerNorm()\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (activ1): Tanh()\n",
      "    (sigmoid): Sigmoid()\n",
      "    (tanh): Tanh()\n",
      "    (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (norm): LayerNorm()\n",
      "    (linear): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (decoder): Linear(in_features=32, out_features=2, bias=False)\n",
      "    (encoder): Linear(in_features=2, out_features=32, bias=False)\n",
      "  )\n",
      ")\n",
      "logging to /home/ahf38/palmer_scratch/cst_release/BERT-50_IE_Spirals/version_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocessing is handled by SLURM.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/gpfs/gibbs/project/dijk/ahf38/conda_envs/cst/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /vast/palmer/scratch/dijk/ahf38/cst_release/BERT-50_IE_Spirals/version_6 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type               | Params\n",
      "---------------------------------------------\n",
      "0 | model | BERT_LinearEncoder | 818 K \n",
      "---------------------------------------------\n",
      "818 K     Trainable params\n",
      "0         Non-trainable params\n",
      "818 K     Total params\n",
      "3.272     Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:01<00:00,  1.02it/s]\n",
      "Best validation loss: 8.263665199279785\n",
      "Saving best model for epoch: 1\n",
      "\n",
      "Epoch 0:  56%|█████▌    | 28/50 [00:03<00:03,  7.19it/s, loss=1.06, v_num=6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/dijk/ahf38/conda_envs/cst/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "# -- load model and parameters for training and logging\n",
    "\n",
    "# -- metadata for saving checkpoints\n",
    "str_model_name = \"BERT\"\n",
    "str_model_type = args.experiment_name# options: linear_encoder; conv_encoder (not implemented yet)\n",
    "str_model = f\"{str_model_name}-{str_model_type}\"\n",
    "str_log_dir = args.root_path\n",
    "\n",
    "path_to_experiment = str_log_dir+'/'+str_model\n",
    "print('path_to_experiment: ',path_to_experiment)\n",
    "txt = os.listdir(path_to_experiment)\n",
    "\n",
    "num_experiments=0\n",
    "for i in txt:\n",
    "    if \"_eval\" not in i:\n",
    "        num_experiments += 1\n",
    "            \n",
    "print('version: ',num_experiments)\n",
    "path_to_save_models = path_to_experiment+'/version_'+str(num_experiments)\n",
    "\n",
    "# -- logger location\n",
    "logger = TensorBoardLogger(str_log_dir, name=str_model,version=num_experiments)\n",
    "\n",
    "\n",
    "# -- model checkpoint callback\n",
    "# -- saves a file like: path/to/dir/sample-epoch=02-val_loss=0.32.ckpt\n",
    "os.makedirs(os.path.join(logger.log_dir, \"plots\"), exist_ok=True) # create dir to avoid path does not exist error\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=f\"{logger.log_dir}/\",\n",
    "    filename=str_model + \"-{epoch:05d}-{val_loss:.6f}-{val_r2:.2f}\",\n",
    "    save_top_k=25,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "# -- early stop callback\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=5000, verbose=False, mode=\"min\", check_finite=False)\n",
    "\n",
    "# -- init model\n",
    "# -- could move these cfgs into functions\n",
    "\n",
    "model_cfg = {\n",
    "    \"model_type\": str_model_type,\n",
    "    \"dim\": 32,\n",
    "    \"fast_attention\": False, # Set to True to use linear attention\n",
    "    \"operation_with_pos_encoding\": \"sum\", # \"concatenate\" or \"sum\". For \n",
    "    \"Lipschitz_regularization\": False,\n",
    "    \"penalty_orthogonality\": 1,\n",
    "    \"Spectral_normalization\": False,\n",
    "    \"dim_ff\": 3072,\n",
    "    \"n_layers\": 4,\n",
    "    \"p_drop_attn\": 0.8,\n",
    "    \"use_softmax\": True,\n",
    "    \"n_heads\": 4,\n",
    "    \"p_drop_hidden\": 0.1,\n",
    "    \"vocab_size\": len(dataloaders[dataloader].dataset),\n",
    "    \"max_len\": args.downsample_points,\n",
    "    \"n_segments\": 1,\n",
    "    \"frame_size\": {'rows': obs_.shape[2], 'cols': obs_.shape[3]}, #184, 208\n",
    "    \"patch_size\": np.array([obs_.shape[2],obs_.shape[3]]), #Num patches = (208/8)*(208/8) = 598 patches/frame. If patch_size is empty, use patch_size==frame_size\n",
    "    \"range_imshow\": None,\n",
    "    \"scale_gauss\": None, \n",
    "    \"plot_predictions\": True,\n",
    "    \"plot_training_curves\": False,\n",
    "    \"plot_every_epochs\": 10,\n",
    "    \"plot_att_weights\" : True,\n",
    "}\n",
    "\n",
    "patch_sampling_cfg = {\n",
    "    \"num_frames\": args.downsample_points, #segment_size, # number of frames to use\n",
    "    \"num_patches\": 6, # number of patches to sample from frames. If patch_size is less than frame_size, num_patches represents the number of frames being selected (temporal sparsity)\n",
    "    \"structure\": \"grid\", # options: random, grid (only used if predicting patches)\n",
    "    \"num_patches_to_hide\": (model_cfg[\"frame_size\"][\"rows\"]//model_cfg[\"patch_size\"][0])*(model_cfg[\"frame_size\"][\"cols\"]//model_cfg[\"patch_size\"][1]),\n",
    "    \"n_frames_to_hide\": args.downsample_points - args.num_seen_points, # if n_frames_to_hide=1, only the last frame is masked and predicted. If >1, 3 random frames of the sequence are used.\n",
    "    \"num_in_between_frames\": 10, # Number of dummy points that will be added\n",
    "    \"in_between_frame_init\": \"interpolation\", # options: 'mask' sets the dummy frames to 0.5; 'random' sets the dummy frames to gaussian with mean 0 and std=0.1; \"inteporlation\" initializes the dummy and masked frames as an inteprolation of the visible frames\n",
    "    \"interpolation_kind\" : \"linear\",\n",
    "    \"batch_size_segments\": args.batch_size,# batch_size_segments,\n",
    "    \"prob_replace_masked_token\": 1.0,\n",
    "    \"sampling_type\" : 'random', #'random' or 'regular'\n",
    "    \"masking_type\" : \"random_masking\",# \"last_n_points\" masks the last n points defined by n_frames_to_hide. \"equal_spaced\" distributes the masked points equally betwen visible ones. \"random_masking\" randomly masks \n",
    "    \"mode\": \"\" # In \"inference\", the frames are chosen manualy \n",
    "} \n",
    "\n",
    "train_cfg = {\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 1e-7 ,\n",
    "    \"segment_size\": str(args.downsample_points), \n",
    "    \"experiment_name\": args.experiment_name,\n",
    "    \"compute_loss_whole_curve\":args.compute_loss_whole_curve,\n",
    "    \"compute_loss_on_dummy_points\":args.compute_loss_on_dummy_points,\n",
    "    \"weight_loss_on_real\" : 0.5,\n",
    "    \"derivtive_order_k\": 3, \n",
    "    \"norm_power_p\": 3, \n",
    "    \"use_mean_sobolev\": False,\n",
    "    \"factor_sobolev\":.01,\n",
    "    \"use_mse\":True,\n",
    "    \"std_noise_t\": 0.,\n",
    "    \"std_to_data\":.1,\n",
    "}\n",
    "\n",
    "loss_func = sobolev_loss(k=train_cfg[\"derivtive_order_k\"],p=train_cfg[\"norm_power_p\"],\n",
    "                         dim=obs_.shape[2],bs=args.batch_size,data_length=20,minimize=True,\n",
    "                         diff_mode='central',factor = train_cfg[\"factor_sobolev\"])\n",
    "\n",
    "model = BERT_Model(model_cfg,\n",
    "                   patch_sampling_cfg,\n",
    "                   train_cfg,my_loss=loss_func,\n",
    "                   path_to_save_models=path_to_save_models,\n",
    "                   warmup=0)\n",
    "\n",
    "if 'resume_from_checkpoint' in train_cfg:\n",
    "    print('Loading BERT checkpoint model {}'.format(train_cfg['resume_from_checkpoint']))\n",
    "    try: \n",
    "        list_of_checkpoints = glob.glob(os.path.join(str_log_dir,str_model,train_cfg['resume_from_checkpoint'],'*.ckpt')) # * means all if need specific format then *.csv\n",
    "        latest_checkpoint = max(list_of_checkpoints, key=os.path.getctime)\n",
    "        print('Loading ', latest_checkpoint)\n",
    "        model = BERT_Model.load_from_checkpoint(latest_checkpoint)\n",
    "    except:\n",
    "        print('Loading failed')\n",
    "    \n",
    "# with open(f\"{logger.log_dir}/readme.txt\", \"w+\") as txt:\n",
    "#     print(readme, file=txt)\n",
    "    \n",
    "print(model)\n",
    "print(f\"logging to {logger.log_dir}\")\n",
    "\n",
    "# -- create pytorch lightning trainer and fit model to data\n",
    "# -- trainer\n",
    "trainer = pl.Trainer(max_epochs=10000,\n",
    "                     accelerator='gpu',\n",
    "                     devices = [args.gpu_id],\n",
    "                     logger=logger,\n",
    "                     fast_dev_run=False, # 'True' to run 1 train, val, test batch and program ends\n",
    "                     enable_progress_bar=True, #'False' to disable the progress bar\n",
    "                     log_every_n_steps=2,\n",
    "                     callbacks=[early_stop_callback,\n",
    "                                checkpoint_callback])\n",
    "\n",
    "trainer.fit(model, dataloaders['train'], dataloaders['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "main (2).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
